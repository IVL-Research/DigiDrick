{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import\n",
    "Script used to read txt and xls files and convert to pickled data files later imported by MembraneAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T12:59:24.886802Z",
     "start_time": "2021-02-26T12:59:22.759455Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "- dataDir = directory file path where txt files are stored (if applicable)\n",
    "- data_file = file path to excel file (if applicable)\n",
    "- result_name = name of result file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T13:21:26.179877Z",
     "start_time": "2021-02-26T13:21:26.158499Z"
    }
   },
   "outputs": [],
   "source": [
    "dataDir = \"path\\to\\folder\\UF_EXPORT_Raw_200401\" \n",
    "data_file = \"path\\to\\UF-fullskaleanl√§ggning_processignaler_jan2018-april2019.xlsx\"\n",
    "result_name = 'joined_data_180101-200401_1m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T12:59:38.505245Z",
     "start_time": "2021-02-26T12:59:38.474246Z"
    }
   },
   "outputs": [],
   "source": [
    "filenames = glob.glob(dataDir + '*.txt') \n",
    "count=1\n",
    "signals = []\n",
    "for file in filenames:\n",
    "    print('Importing file ' + str(count) + ' out of ' + str(len(filenames)))\n",
    "    sensor_data = pd.read_csv(file, delimiter='\\t')\n",
    "    col = sensor_data.index\n",
    "    index = []\n",
    "    value = []\n",
    "    for ix in range(len(col)):\n",
    "        index.append(col[:][ix][0])\n",
    "        value.append(col[:][ix][1])\n",
    "            \n",
    "    key = {'JAN':'01', 'FEB':'02', 'MAR':'03', 'APR':'04', 'MAJ':'05', 'JUN':'06', 'JUL':'07', 'AUG':'08', 'SEP':'09', 'OKT':'10', 'NOV':'11', 'DEC':'12'}\n",
    "    index_mod = []\n",
    "    for date in index:\n",
    "        for month, num in key.items():\n",
    "            date = date.replace(month, num)\n",
    "        index_mod.append(date)\n",
    "\n",
    "    index_dt = pd.to_datetime(index_mod, dayfirst=True)\n",
    "    signals.append(pd.DataFrame(data=value, index=index_dt, columns=[sensor_data.columns[0]]))\n",
    "    count += 1\n",
    "\n",
    "    \n",
    "txt_data = pd.DataFrame()\n",
    "for s in signals:\n",
    "    txt_data = txt_data.join(s, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Excel-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T13:11:03.742002Z",
     "start_time": "2021-02-26T13:00:09.228394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing: Janurari 2018\n",
      "Importing: Februari 2018\n",
      "Importing: Mars 2018\n",
      "Importing: April 2018\n",
      "Importing: Maj 2018\n",
      "Importing: Juni 2018\n",
      "Importing: Juli 2018\n",
      "Importing: Augusti 2018\n",
      "Importing: September 2018\n",
      "Importing: Oktober 2018\n",
      "Importing: November 2018\n",
      "Importing: December 2018\n",
      "Importing: Januari 2019\n",
      "Importing: Februari 2019\n",
      "Importing: Mars 2019\n",
      "Importing: April 2019\n"
     ]
    }
   ],
   "source": [
    "xl = pd.ExcelFile(data_file,engine=\"openpyxl\")\n",
    "sheet_names = xl.sheet_names\n",
    "excel_data = pd.DataFrame()\n",
    "for sheet in sheet_names[1:]:\n",
    "    print('Importing: ' + sheet)\n",
    "    df = pd.read_excel(xl, sheet_name=sheet)  # Import data file to pandas Dataframe\n",
    "    df.index = df['Tid']\n",
    "    df = df.drop(['Tid'], axis=1)\n",
    "    excel_data = pd.concat([excel_data, df])\n",
    "\n",
    "excel_data = excel_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge and store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T13:21:32.931856Z",
     "start_time": "2021-02-26T13:21:29.284220Z"
    }
   },
   "outputs": [],
   "source": [
    "joined_data = pd.concat([excel_data, txt_data])\n",
    "joined_data_resampled = joined_data.resample('1T').median().ffill()\n",
    "joined_data_resampled.to_pickle(result_name + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
